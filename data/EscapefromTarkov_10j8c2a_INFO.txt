{"Title": "An audio engineers take on why the switch to Oculus was a bad move", "Post Text": "Previously with steam audio we had HRTF (binaural) which simulates the latency of sound arriving in each ear to help with localisation ([i've got a post that explains in more detail here](https://www.reddit.com/r/EscapefromTarkov/comments/8n7r1v/how_to_improve_sound_localisation_hrtf_occlusion/)). This seems to be non-functional in the current implementation of Oculus, likely a bug.\n\nWe also had occlusion, which simulates the filtering effect walls would have (low frequencies can travel through walls, high frequencies reflect so can't pass through).\n\nTo simulate occlusion, BSG placed occlusion zones around the maps. If an occlusion zone is between the player and the sound emitter, a filtering effect is applied. This basic implementation caused a lot of issues. The best example being staircases. The filtering effect seemed to be fairly binary, so someone approaching you from a staircase could make very little to no noise until they reached the same floor as you. If you're sat on the staircase, that means they would be right behind you.\n\nI believe BSG moved to Oculus to try and solve the problem with their manually placed occlusion zones.\n\n&#x200B;\n\n>The Audio Propagation feature of the Oculus Audio SDK provides real-time reverb and occlusion simulation based on game geometry. Its goal is to provide accurate audio propagation through a scene with minimal set up.\n\n([https://developer.oculus.com/documentation/unity/audio-spatializer-features/](https://developer.oculus.com/documentation/unity/audio-spatializer-features/))\n\nBy basing the occlusion on game geometry, it removes the need for manually placed occlusion zones. I can see why BSG did this in theory, although I think in the long run this will be a huge mistake. Check this from the Oculus Audio documentation:\n\n>the audio propagation system models occlusion with a simple line-of-sight calculation, and does not model diffraction. That means that the transition from audible to obstructed can be abrupt and may require some adjustments.\n\n([https://developer.oculus.com/documentation/unity/audio-osp-unity-propagation/](https://developer.oculus.com/documentation/unity/audio-osp-unity-propagation/))\n\nNow check out some clips from Onepegs video demonstrating the new audio implementation on Shoreline:\n\n[https://www.youtube.com/watch?v=-mLhJ1FCFyA](https://www.youtube.com/watch?v=-mLhJ1FCFyA)\n\nYou can really hear the abruptness mentioned...\n\nThe fix for this would be to implement path tracing. A good analogy is to think of Ray Tracing and light sources bouncing dynamically. There's a guy running on the floor below you, the floor would muffle that. The sound of running would bounce of the walls up the open staircase. In real life you would hear the sound emitting from the staircase. The sound would be quieter and more diffuse/reverberated, and become louder and dryer the close it got.\n\nThis can be implemented with wave tracing, similar to ray tracing. But that's very computationally expensive. A workaround that's been used in other games is path tracing. Paths are manually baked in to maps simulate sound propagation. Take a look at this R6 siege demonstration to get a better idea: [https://www.youtube.com/watch?v=ti6ZWRSiqpQ](https://www.youtube.com/watch?v=ti6ZWRSiqpQ)\n\nFor contrast, here's an example of steam audios HRTF + Occlusion being used without path tracing:[https://www.youtube.com/watch?v=5R\\_32a3a0eM](https://www.youtube.com/watch?v=5R_32a3a0eM)\n\nYou can hear the sound getting filtered, but the location of the sound still emits directly though the wall, rather than from the door as it should.\n\nUnfortunately Oculus Audio lacks the path tracing feature:\n\n&#x200B;\n\n>Sounds interact with a user\u2019s environment in many ways. Objects and walls may obstruct, reflect, or propagate a sound through the virtual world. The SDK only supports direct reflections and does not factor in the virtual world geometry. This problem needs to be solved at a higher level than the Oculus Audio SDK due to the requirements of scanning and referencing world geometry.\n\n([https://developer.oculus.com/documentation/unity/audio-spatializer-features/](https://developer.oculus.com/documentation/unity/audio-spatializer-features/))\n\nThis doesn't mean it couldn't be implemented with Oculus Audio, but BSG would need to develop and integrate their own path tracing system. This is a very specialised job requiring expert knowledge in both audio engineering and game development. Not an easy feat to accomplish.\n\nSteam Audio did have a path tracing effect [https://valvesoftware.github.io/steam-audio/doc/capi/path-effect.html](https://valvesoftware.github.io/steam-audio/doc/capi/path-effect.html)\n\nNot sure if BSG ever tried to implement this, as the switch to Oculus would make no sense due to the lack of path tracing feature. Unless BSG is planning on developing their own path tracing feature which I'm doubtful of.\n\n**EDIT:**\n\n/u/Leeps **mentioned Microsoft Project Acoustics which has a unity plugin:**\n\n[**https://learn.microsoft.com/en-us/gaming/acoustics/what-is-acoustics**](https://learn.microsoft.com/en-us/gaming/acoustics/what-is-acoustics)\n\n**This could potentially be a great solution for Tarkov so putting it here for visibility.**", "ID": "10j8c2a", "Score": 1211, "Total Comments": 236, "Post URL": "https://www.reddit.com/r/EscapefromTarkov/comments/10j8c2a/an_audio_engineers_take_on_why_the_switch_to/"}