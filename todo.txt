MAIN TASKS
 - do bigger scrapes, we need more posts and comments in general
	- 200 posts from top month?
	- all top level comments from each post?

- change network notebook to use functions that can be put together to work on any given subreddit
	- exclude self loops (posters that have commented on their own post)
	- directed edges
	- save final datasets so we dont have to rerun things
	- save gephx / gephi files for each subreddit network

 - try running michele algorithm

 - investigate post embeddings by visualizing and seeing if users posting similar topics are in close proximity
	- do they make sense?

EXTRA TASKS

data cleaning:
 - exclude bot comments?
 - exclude auto-mod comments?