{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for using the notebook\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from embedding_functions_hugo.embedding_functions import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying datasets from different reddit pages\n",
    "\n",
    "# df_gaming = pd.read_csv('../data/scrapes/gaming.csv')\n",
    "# df_satis = pd.read_csv('../data/scrapes/SatisfactoryGame.csv')\n",
    "# df_marauders = pd.read_csv('../data/scrapes/MaraudersGame.csv')\n",
    "# df_tarkov = pd.read_csv('../data/scrapes/EscapefromTarkov.csv')\n",
    "df_politics = pd.read_csv('../data/scrapes/politics.csv')\n",
    "\n",
    "\n",
    "# Datasets post cleaning the text\n",
    "# df_politics['cleaned_text'] = prep_pipeline(df_politics, 'comment_text')\n",
    "# df_politics['short'] = shorten_sens(df_politics['cleaned_text'], 50)\n",
    "\n",
    "# Function to speed up the process: \n",
    "\n",
    "def shorten_and_clean_dataset (comment_csv, comment_column : str, desired_comment_length : int):\n",
    "    dataframe = pd.read_csv(comment_csv)\n",
    "    dataframe['cleaned_text'] = prep_pipeline(dataframe, comment_column)\n",
    "    dataframe['short'] = shorten_sens(dataframe['cleaned_text'], desired_comment_length)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sen_leng = []\n",
    "# for i in df_politics['short']:\n",
    "#     sen_leng.append(len(i.split()))\n",
    "\n",
    "\n",
    "# print(np.percentile(sen_leng, 25))\n",
    "# print(np.percentile(sen_leng, 50))\n",
    "# print(np.percentile(sen_leng, 75))\n",
    "# print(np.percentile(sen_leng, 99))\n",
    "# print(np.mean(sen_leng))\n",
    "# print(np.median(sen_leng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors = df_politics.values[:,-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings_as_npy(destination_path : str, comment_csv, comment_column : str, desired_comment_length : int):\n",
    "    from numpy import savetxt\n",
    "    '''\n",
    "    Nlp pipeline function which takes a pandas dataframe and relevant columns, performs preprocessing steps, uses sentence_transformer embeddings and saves the embeddings as a csv file.\n",
    "    '''\n",
    "    sentences = shorten_and_clean_dataset(comment_csv, comment_column, desired_comment_length)\n",
    "    embeddings = embed_comments(sentences['short'])\n",
    "    return np.save(destination_path, embeddings)\n",
    "   # return savetxt(destination_path, embeddings, delimiter = ',')\n",
    "\n",
    "### UNCOMMENT BELOW TO DO EMBEDDINGS AND SAVE THEM\n",
    "\n",
    "# save_embeddings_as_npy('../data/embeddings/politics_embeddings.npy', '../data/scrapes/politics.csv', 'comment_text', 50)\n",
    "# save_embeddings_as_npy('../data/embeddings/gaming_embeddings.npy', '../data/scrapes/gaming.csv', 'comment_text', 50)\n",
    "save_embeddings_as_npy('../data/embeddings/marauders_embeddings.npy', '../data/scrapes/MaraudersGame.csv', 'comment_text', 50)\n",
    "# save_embeddings_as_npy('../data/embeddings/tarkov_embeddings.npy', '../data/scrapes/EscapefromTarkov.csv', 'comment_text', 50)\n",
    "# save_embeddings_as_npy('../data/embeddings/satisfactory_embeddings.npy', '../data/scrapes/SatisfactoryGame.csv', 'comment_text', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_users_embeddings(dataframe, embeddings, average_out_comments = False):\n",
    "    usernames = dataframe['comment_author']\n",
    "    user_dictionary = {}\n",
    "    for author, embedded_comment in zip(usernames, embeddings):\n",
    "        if author not in user_dictionary.keys():\n",
    "            user_dictionary[author] = []\n",
    "            user_dictionary[author].append(embedded_comment)\n",
    "        else:\n",
    "            user_dictionary[author].append(embedded_comment)\n",
    "    if average_out_comments:\n",
    "        for user in user_dictionary:\n",
    "            number_or_comments = len(user_dictionary[user])\n",
    "            user_dictionary[user] = sum(user_dictionary[user])/number_or_comments\n",
    "    return user_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING EMBEDDINGS FROM FILES\n",
    "\n",
    "politics_embeddings = np.load('../data/embeddings/politics_embeddings.npy')\n",
    "gaming_embeddings = np.load('../data/embeddings/gaming_embeddings.npy')\n",
    "marauders_embeddings = np.load('../data/embeddings/marauders_embeddings.npy')\n",
    "tarkov_embeddings = np.load('../data/embeddings/tarkov_embeddings.npy')\n",
    "\n",
    "# include below when the satisfactory embeddings are done\n",
    "# satisfactory_embeddings = np.load('../data/embeddings/satisfactory_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics_user_embeddings = pair_users_embeddings(df_politics, politics_embeddings, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "two_dimensional_embeddings = pca.fit_transform(list(politics_user_embeddings.values()))\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "\n",
    "classes = kmeans.fit_predict(two_dimensional_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dims_and_kmeans(user_embedding_pairs, num_of_dimensions):\n",
    "    '''\n",
    "    Current version only works w 2 colors. \n",
    "    '''\n",
    "    # Set PCA to desired number of dimensions\n",
    "    pca = PCA(n_components=num_of_dimensions)\n",
    "\n",
    "\n",
    "    pca_embeddings = pca.fit_transform(list(user_embedding_pairs.values()))\n",
    "\n",
    "    kmeans = KMeans(n_clusters=2, random_state=0) \n",
    "\n",
    "    classes = kmeans.fit_predict(pca_embeddings)\n",
    "\n",
    "\n",
    "    label_color_map = {0 : 'r',1 : 'g'}\n",
    "    label_color = [label_color_map[l] for l in classes]\n",
    "    plt.scatter(pca_embeddings[:,0], pca_embeddings[:,1], c=label_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_dims_and_kmeans(politics_user_embeddings, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
