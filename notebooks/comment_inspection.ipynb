{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92b69f45",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907fb282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, SpectralClustering, BisectingKMeans, AgglomerativeClustering, FeatureAgglomeration\n",
    "import matplotlib.pyplot as plt\n",
    "from embedding_functions_hugo.embedding_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e8276e",
   "metadata": {},
   "source": [
    "# Data Grabbing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45ae085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subreddit dataframes with comments\n",
    "df_gaming = pd.read_csv('../data/scrapes/gaming.csv')\n",
    "df_satis = pd.read_csv('../data/scrapes/SatisfactoryGame.csv')\n",
    "df_marauders = pd.read_csv('../data/scrapes/MaraudersGame.csv')\n",
    "df_tarkov = pd.read_csv('../data/scrapes/EscapefromTarkov.csv')\n",
    "df_politics = pd.read_csv('../data/scrapes/politics.csv')\n",
    "\n",
    "# LOADING EMBEDDINGS FROM FILES\n",
    "politics_embeddings = np.load('../data/embeddings/politics_embeddings.npy')\n",
    "gaming_embeddings = np.load('../data/embeddings/gaming_embeddings.npy')\n",
    "marauders_embeddings = np.load('../data/embeddings/marauders_embeddings.npy')\n",
    "tarkov_embeddings = np.load('../data/embeddings/tarkov_embeddings.npy')\n",
    "satisfactory_embeddings = np.load('../data/embeddings/satisfactory_embeddings.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4eb0cf",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c79414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortening and cleaning function\n",
    "def shorten_and_clean_dataset (comment_csv, comment_column : str, desired_comment_length : int):\n",
    "    dataframe = pd.read_csv(comment_csv)\n",
    "    dataframe['cleaned_text'] = prep_pipeline(dataframe, comment_column)\n",
    "    dataframe['short'] = shorten_sens(dataframe['cleaned_text'], desired_comment_length)\n",
    "    return dataframe\n",
    "\n",
    "# function for creating and saving embeddings\n",
    "def save_embeddings_as_npy(destination_path : str, comment_csv, comment_column : str, desired_comment_length : int):\n",
    "    '''\n",
    "    Nlp pipeline function which takes a pandas dataframe and relevant columns, performs preprocessing steps, uses sentence_transformer embeddings and saves the embeddings as a csv file.\n",
    "    '''\n",
    "    sentences = shorten_and_clean_dataset(comment_csv, comment_column, desired_comment_length)\n",
    "    embeddings = embed_comments(sentences['short'])\n",
    "    return np.save(destination_path, embeddings)\n",
    "\n",
    "def pair_users_embeddings(dataframe, embeddings, average_out_comments = False):\n",
    "    usernames = dataframe['comment_author']\n",
    "    user_dictionary = {}\n",
    "    for author, embedded_comment in zip(usernames, embeddings):\n",
    "        if author not in user_dictionary.keys():\n",
    "            user_dictionary[author] = []\n",
    "            user_dictionary[author].append(embedded_comment)\n",
    "        else:\n",
    "            user_dictionary[author].append(embedded_comment)\n",
    "    if average_out_comments:\n",
    "        for user in user_dictionary:\n",
    "            number_or_comments = len(user_dictionary[user])\n",
    "            user_dictionary[user] = sum(user_dictionary[user])/number_or_comments\n",
    "    return user_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111e0f19",
   "metadata": {},
   "source": [
    "# Comment Inspection\n",
    "\n",
    "## Quick Prep (r/politics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ed691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "politics_user_embeddings = pair_users_embeddings(df_politics, politics_embeddings, True)\n",
    "\n",
    "# Set PCA to desired number of dimensions\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "pca_embeddings = pca.fit_transform(list(politics_user_embeddings.values()))\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "\n",
    "classes = kmeans.fit_predict(pca_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7e0a2a",
   "metadata": {},
   "source": [
    "## Horizontally distant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9164b49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pca_embeddings.shape)\n",
    "#print(len(politics_user_embeddings.keys()), len(politics_user_embeddings.values()))\n",
    "\n",
    "# finding indexes of rows with least and max x values\n",
    "\n",
    "x_vals = []\n",
    "for idx, row in enumerate(pca_embeddings):\n",
    "    x_val = row[0]\n",
    "    x_vals.append(x_val)\n",
    "\n",
    "# least x\n",
    "least_x = min(x_vals)\n",
    "least_x_index = np.argmin(x_vals)\n",
    "least_x_username = list(politics_user_embeddings.keys())[least_x_index]\n",
    "least_x_comments = df_politics.loc[df_politics['comment_author'] == least_x_username]\n",
    "\n",
    "max_x = max(x_vals)\n",
    "max_x_index = np.argmax(x_vals)\n",
    "max_x_username = list(politics_user_embeddings.keys())[max_x_index]\n",
    "max_x_comments = df_politics.loc[df_politics['comment_author'] == max_x_username]\n",
    "\n",
    "#print(least_x, least_x_index, least_x_username)\n",
    "#print(max_x, max_x_index, max_x_username)\n",
    "\n",
    "#print(df_politics.shape)\n",
    "#print(len(politics_user_embeddings.keys()))\n",
    "print('===== Lowest x coord comment =====')\n",
    "print(least_x_comments['comment_text'].values[0])\n",
    "print('\\n===== Highest x coord comment =====')\n",
    "print(max_x_comments['comment_text'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fbc11a",
   "metadata": {},
   "source": [
    "## Vertically distant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d225e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pca_embeddings.shape)\n",
    "#print(len(politics_user_embeddings.keys()), len(politics_user_embeddings.values()))\n",
    "\n",
    "# finding indexes of rows with least and max y values\n",
    "\n",
    "y_vals = []\n",
    "for idx, row in enumerate(pca_embeddings):\n",
    "    y_val = row[1]\n",
    "    y_vals.append(y_val)\n",
    "\n",
    "# least y\n",
    "least_y = min(y_vals)\n",
    "least_y_index = np.argmin(y_vals)\n",
    "least_y_username = list(politics_user_embeddings.keys())[least_y_index]\n",
    "least_y_comments = df_politics.loc[df_politics['comment_author'] == least_y_username]\n",
    "\n",
    "max_y = max(y_vals)\n",
    "max_y_index = np.argmax(y_vals)\n",
    "max_y_username = list(politics_user_embeddings.keys())[max_y_index]\n",
    "max_y_comments = df_politics.loc[df_politics['comment_author'] == max_y_username]\n",
    "\n",
    "#print(least_y, least_y_index, least_y_username)\n",
    "#print(max_y, max_y_index, max_y_username)\n",
    "\n",
    "#print(df_politics.shape)\n",
    "#print(len(politics_user_embeddings.keys()))\n",
    "print('===== Lowest y coord comment =====')\n",
    "print(least_y_comments['comment_text'].values[0])\n",
    "print()\n",
    "print('===== Highest y coord comment =====')\n",
    "print(max_y_comments['comment_text'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f121e39",
   "metadata": {},
   "source": [
    "## Most distant (in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324c0c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b04590f5",
   "metadata": {},
   "source": [
    "## Similar Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133ba13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar(df, embeddings):\n",
    "    '''inputs:\n",
    "        - df: df to work with\n",
    "        - embeddings: embeddings to work with\n",
    "       \n",
    "       function finds all users that fit in the limits and are therefore similar,\n",
    "       then prints their comments'''\n",
    "    \n",
    "    # pairing embeddings\n",
    "    user_embeddings = pair_users_embeddings(df, embeddings, True)\n",
    "    \n",
    "    # doing pca things\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_embeddings = pca.fit_transform(list(user_embeddings.values()))\n",
    "    kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "    classes = kmeans.fit_predict(pca_embeddings)\n",
    "    \n",
    "    # print blob\n",
    "    label_color_map = {0 : 'r',1 : 'g'}\n",
    "    label_color = [label_color_map[l] for l in classes]\n",
    "    plt.scatter(pca_embeddings[:,0], pca_embeddings[:,1], c=label_color)\n",
    "    \n",
    "    # finding similar things\n",
    "    # NEED TO CODE FOR FINDING ALL FAR THINGS\n",
    "    to_check = ['MIDDLE', 'LEFT', 'RIGHT', 'TOP', 'BOTTOM']\n",
    "    \n",
    "    for i in to_check:\n",
    "        \n",
    "        # finding x and y limits based off of blob\n",
    "        \n",
    "        if i == 'MIDDLE':\n",
    "            print('========== MIDDLE ==========')\n",
    "            x_lims = [-0.1, 0.1]\n",
    "            y_lims = [-0.1, 0.1]\n",
    "            \n",
    "            similar_indexes = list()\n",
    "            for idx, row in enumerate(pca_embeddings):\n",
    "                x_val = row[0]\n",
    "                y_val = row[1]\n",
    "                \n",
    "                if x_val > x_lims[0] and x_val < x_lims[1] and y_val > y_lims[0] and y_val < y_lims[1]:\n",
    "                    similar_indexes.append(idx)\n",
    "        \n",
    "        # checks from far left and finds first 5 comments\n",
    "        elif i == 'LEFT':\n",
    "            print('========== LEFT ==========')\n",
    "            # get list of x coords for sorting\n",
    "            x_coords = list()\n",
    "            for idx, row in enumerate(pca_embeddings):\n",
    "                x_coords.append(row[0])\n",
    "            \n",
    "            # sorts x coords by ascending, but gives the indexes not the values\n",
    "            sorted_indexes = np.argsort(x_coords)\n",
    "            \n",
    "            similar_indexes = sorted_indexes[:5]\n",
    "        \n",
    "        # checks from far left and finds first 5 comments\n",
    "        elif i == 'RIGHT':\n",
    "            print('========== RIGHT ==========')\n",
    "            # get list of x coords for sorting\n",
    "            x_coords = list()\n",
    "            for idx, row in enumerate(pca_embeddings):\n",
    "                x_coords.append(row[0])\n",
    "            \n",
    "            # sorts x coords by descending, but gives the indexes not the values\n",
    "            initial_sort = np.argsort(x_coords)\n",
    "            \n",
    "            similar_indexes = initial_sort[::-1][:5] # 5 for first 5 comments\n",
    "        \n",
    "        # checks from far top and finds first 5 comments\n",
    "        elif i == 'TOP':\n",
    "            print('========== TOP ==========')\n",
    "            # get list of y coords for sorting\n",
    "            y_coords = list()\n",
    "            for idx, row in enumerate(pca_embeddings):\n",
    "                y_coords.append(row[1])\n",
    "            \n",
    "            # sorts y coords by descending, but gives the indexes not the values\n",
    "            initial_sort = np.argsort(y_coords)\n",
    "            \n",
    "            similar_indexes = initial_sort[::-1][:5] # 5 for first 5 comments\n",
    "        \n",
    "        elif i == 'BOTTOM':\n",
    "            print('========== BOTTOM ==========')\n",
    "            # get list of y coords for sorting\n",
    "            y_coords = list()\n",
    "            for idx, row in enumerate(pca_embeddings):\n",
    "                y_coords.append(row[1])\n",
    "            \n",
    "            # sorts y coords by ascending, but gives the indexes not the values\n",
    "            sorted_indexes = np.argsort(y_coords)\n",
    "            \n",
    "            similar_indexes = sorted_indexes[:5]\n",
    "            \n",
    "        # using list of similar indexes, matches with users and prints their comments\n",
    "        usernames = list()\n",
    "        for index in similar_indexes:\n",
    "            username = list(user_embeddings.keys())[index]\n",
    "            usernames.append(username)\n",
    "\n",
    "        # cleaning comments to get relevant ones in embedding space\n",
    "        df['cleaned_text'] = prep_pipeline(df, 'comment_text')\n",
    "        df['short'] = shorten_sens(df['cleaned_text'], 50)\n",
    "        \n",
    "        for username in usernames:\n",
    "            comments = df.loc[df['comment_author'] == username]\n",
    "            #print(comments['comment_text'].values[0], '\\n')\n",
    "            print(comments['short'].values[0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfd9da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_similar(df_politics, politics_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e0f100",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_similar(df_gaming, gaming_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d75787",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_similar(df_marauders, marauders_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf9289d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf72dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
